
"""Module with tools for the project"""

import tiktoken
from tqdm import tqdm
import os


class ProgressBar:

    """
    ### ‚è≥ Progress Bar
    Class to display a progress bar using the tqdm library

    ### üìù Parameters:

        üîπ `total: int` - The total number of steps for the progress bar
        üîπ `description: str` - The description displayed next to the progress bar (default: 'Processing')
        üîπ `variable: str` - The unit of measurement displayed on the progress bar (default: 'items')

    ### ‚öôÔ∏è How to use:
    ```python
    from Tools.tools import ProgressBar

    pbar = ProgressBar(total=100, description="Loading", variable="files")
    for i in range(100):
        # your processing code here
        pbar.update(1)
    pbar.close()
    ```
    """

    def __init__(self, total, description="Processing", variable="items") -> None:

        self.pbar = tqdm(total=total, desc=description, unit=variable)

    def update(self, n):
        """
        Update the progress bar by a given number of steps.

        Parameters:
        - n (int): Number of steps to update the progress bar by.
        """
        self.pbar.update(n)

    def reset(self):
        """
        Reset the progress bar.
        """
        self.pbar.reset()

    def close(self):
        """
        Close the progress bar.
        """
        self.pbar.close()


def count_tokens(file_path, model_name, mode):
    """
    ### üî¢ Contador de Tokens
    Fun√ß√£o para contar tokens de um arquivo ou string e calcular o pre√ßo com suporte aos modelos mais recentes (junho/agosto 2024)

    ### üìù Parameters:

        üîπ `file_path: str` - O caminho para o arquivo ou a string para contar os tokens
        üîπ `model_name: str` - O nome do modelo a ser usado para contagem
        üîπ `mode: str` - "input" ou "output" para determinar o pre√ßo

    ### üîÑ Returns:
        üîπ `tuple` - (n√∫mero de tokens, pre√ßo)

    ### ‚öôÔ∏è Como usar:
    ```python
    from Tools.tools import count_tokens
    n_tokens, preco = count_tokens("meuarquivo.txt", "gpt-4.1", "input")
    ```
    """
    try:
        num_tokens = 0
        price = 0
        factor = 0
        text = ""

        # Pre√ßos atualizados (junho/agosto 2024)
        # Refer√™ncias: OpenAI, Google Gemini
        # Valores em d√≥lares por 1.000 tokens
        model_pricing = {
            # OpenAI
            "gpt-4.1": {"input": 0.00200, "output": 0.00800},
            "gpt-4o": {"input": 0.00250, "output": 0.01000},
            "gpt-4o-2024-08-06": {"input": 0.00250, "output": 0.01000},
            "gpt-4o-mini": {"input": 0.000150, "output": 0.00060},
            # Gemini
            "gemini-1.5-pro": {"input": 0.00350, "output": 0.01050},
            "gemini-1.5-flash": {"input": 0.000075, "output": 0.00030},
        }

        # Normaliza√ß√£o do nome do modelo
        model_key = model_name.lower().replace(" ", "-")
        if "gemini" in model_key and "flash" in model_key:
            model_key = "gemini-1.5-flash"
        elif "gemini" in model_key:
            model_key = "gemini-1.5-pro"
        elif "gpt-4.1" in model_key:
            model_key = "gpt-4.1"
        elif "gpt-4o-mini" in model_key:
            model_key = "gpt-4o-mini"
        elif "gpt-4o" in model_key:
            model_key = "gpt-4o"
        elif "gpt-3.5" in model_key:
            # GPT-3.5 Turbo (mantido para compatibilidade)
            model_pricing["gpt-3.5-turbo"] = {"input": 0.00050, "output": 0.00150}
            model_key = "gpt-3.5-turbo"
        else:
            raise ValueError(f"Modelo n√£o suportado: {model_name}")

        if mode not in ["input", "output"]:
            raise ValueError("O par√¢metro 'mode' deve ser 'input' ou 'output'.")

        if model_key not in model_pricing:
            raise ValueError(f"Modelo n√£o suportado: {model_name}")

        factor = model_pricing[model_key][mode] / 1000  # pre√ßo por token

        # Leitura do texto
        if os.path.isfile(file_path):
            with open(file_path, "r", encoding="utf-8") as file:
                text = file.read()
        else:
            text = file_path

        # Contagem de tokens
        if "gemini" in model_key:
            num_tokens = len(text) // 4
        else:
            try:
                enc = tiktoken.encoding_for_model(model_name)
                tokens = enc.encode(text)
                num_tokens = len(tokens)
            except Exception as e:
                raise RuntimeError(f"Erro ao codificar tokens: {str(e)}")

        price = num_tokens * factor

        print(f"Number of tokens: {num_tokens}")
        print(f"The price is: $ {price}")

        return num_tokens, price

    except Exception as e:
        raise RuntimeError(f"Erro ao contar tokens: {str(e)}")


